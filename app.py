# app.py - Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ 2025 - Ù…Ø¶Ù…ÙˆÙ† Ø¶Ø¯ Cloudflare
import streamlit as st
import nodriver as uc
from nodriver.cdp import network
import asyncio
import random
import pandas as pd
from datetime import datetime, timedelta
import ttl_cache
import json
import base64
from urllib.parse import quote

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± - Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©", layout="wide", page_icon="ğŸ›’")
st.title("ğŸ›’ Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ - Ø£Ø±Ø®Øµ ØªØ³ÙˆÙ‚ ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© 2025")
st.markdown("### Ø§Ø¯Ø®Ù„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø´ØªØ±ÙŠØ§ØªÙƒ ÙˆØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† 6 Ù…ØªØ§Ø¬Ø± ÙƒØ¨Ø±Ù‰ ÙÙŠ Ø«ÙˆØ§Ù†ÙŠ!")

# Cache Ù„Ù…Ø¯Ø© 6 Ø³Ø§Ø¹Ø§Øª
@ttl_cache.ttl_cache(maxsize=500, ttl=6*60*60)
async def scrape_store(product_name, store_name, city="Riyadh", proxy=None):
    config = uc.Config()
    config.headless = True
    config.user_data_dir = './tmp_profile'
    config.suppress_welcome = True
    config.disable_images = True
    config.proxy_server = proxy

    try:
        browser = await uc.start(config=config)
        page = await browser.get(f"about:blank")
        
        # ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù€ Stealth Ø§Ù„ÙƒØ§Ù…Ù„
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {get: () => false});
            window.chrome = { runtime: {}, app: {}, webstore: {} };
            Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3]});
            Object.defineProperty(navigator, 'languages', {get: () => ['ar-SA', 'ar']});
        """)

        urls = {
            "Ø§Ù„Ø¯Ø§Ù†ÙˆØ¨": f"https://danube.sa/en/search?query={quote(product_name)}",
            "ÙƒØ§Ø±ÙÙˆØ±": f"https://www.carrefourksa.com/mafsau/ar/search/?text={quote(product_name)}",
            "Ø¨Ù†Ø¯Ù‡": f"https://www.panda.com.sa/search?q={quote(product_name)}",
            "Ù„ÙˆÙ„Ùˆ": f"https://www.luluhypermarket.com/ar/search?q={quote(product_name)}",
            "Ø§Ù„Ø¹Ø«ÙŠÙ…": f"https://www.othaimmarkets.com/search/?text={quote(product_name)}",
            "ØªÙ…ÙŠÙ…ÙŠ": f"https://tamimimarkets.com/search?query={quote(product_name)}"
        }

        url = urls.get(store_name)
        if not url:
            return None, None

        await page.get(url, timeout=30)
        await asyncio.sleep(random.uniform(3, 7))

        price = None
        link = None

        if store_name == "Ø§Ù„Ø¯Ø§Ù†ÙˆØ¨":
            await page.wait_for_selector('.product-item', timeout=10)
            first = await page.query_selector('.product-item a')
            if first:
                link = await first.get_attribute('href')
                price_elem = await first.query_selector('.price')
                if price_elem:
                    text = await price_elem.inner_text()
                    price = float(''.join(filter(str.isdigit, text.replace('.', '').replace(',', ''))) / 100)

        elif store_name == "ÙƒØ§Ø±ÙÙˆØ±":
            await page.wait_for_selector('[data-testid="product-card"]', timeout=10)
            first = await page.query_selector('[data-testid="product-card"] a')
            if first:
                link = "https://www.carrefourksa.com" + await first.get_attribute('href')
                price_elem = await first.query_selector('[data-testid="price"]')
                if price_elem:
                    text = await price_elem.inner_text()
                    price = float(text.replace('Ø±.Ø³.', '').replace(',', '').strip())

        elif store_name == "Ø¨Ù†Ø¯Ù‡":
            await page.wait_for_selector('.product-card', timeout=10)
            first = await page.query_selector('.product-card a')
            if first:
                link = await first.get_attribute('href')
                if not link.startswith('http'):
                    link = "https://www.panda.com.sa" + link
                price_elem = await first.query_selector('.price')
                if price_elem:
                    text = await price_elem.inner_text()
                    price = float(text.replace('SAR', '').replace(',', '').strip())

        elif store_name == "Ù„ÙˆÙ„Ùˆ":
            await page.wait_for_selector('.product-box', timeout=10)
            first = await page.query_selector('.product-box a')
            if first:
                link = await first.get_attribute('href')
                price_elem = await first.query_selector('.price')
                if price_elem:
                    text = await price_elem.inner_text()
                    price = float(text.replace('SR', '').replace(',', '').strip())

        elif store_name == "Ø§Ù„Ø¹Ø«ÙŠÙ…":
            await page.wait_for_selector('.product-item', timeout=10)
            first = await page.query_selector('.product-item a')
            if first:
                link = await first.get_attribute('href')
                price_elem = await first.query_selector('.price-now')
                if price_elem:
                    text = await price_elem.inner_text()
                    price = float(text.replace('Ø±.Ø³', '').replace(',', '').strip())

        elif store_name == "ØªÙ…ÙŠÙ…ÙŠ":
            await page.wait_for_selector('.product', timeout=10)
            first = await page.query_selector('.product a')
            if first:
                link = await first.get_attribute('href')
                price_elem = await first.query_selector('.price')
                if price_elem:
                    text = await price_elem.inner_text()
                    price = float(text.replace('SAR', '').replace(',', '').strip())

        await browser.stop()
        return price, link if link else url

    except Exception as e:
        return None, None

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
col1, col2 = st.columns([3, 1])
with col1:
    products_text = st.text_area(
        "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª (ÙƒÙ„ Ù…Ù†ØªØ¬ ÙÙŠ Ø³Ø·Ø±):",
        height=200,
        placeholder="Ø­Ù„ÙŠØ¨ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© 1 Ù„ØªØ±\nØ®Ø¨Ø² ØªÙˆØ³Øª Ø£Ø¨ÙŠØ¶\nØ¨ÙŠØ¶ 30 Ø­Ø¨Ø©\nØ¯Ø¬Ø§Ø¬ Ø·Ø§Ø²Ø¬ 1 ÙƒØ¬Ù…"
    )
with col2:
    city = st.selectbox("Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", ["Ø§Ù„Ø±ÙŠØ§Ø¶", "Ø¬Ø¯Ø©", "Ø§Ù„Ø¯Ù…Ø§Ù…", "Ù…ÙƒØ©", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ù†ÙˆØ±Ø©"])
    use_proxy = st.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø±ÙˆÙƒØ³ÙŠØ§Øª Ø¯ÙˆØ§Ø±Ø© (Ù…ÙˆØµÙ‰ Ø¨Ù‡)", value=True)
    proxy_input = st.text_area(
        "Ù„ØµÙ‚ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¨Ø±ÙˆÙƒØ³ÙŠØ§Øª (ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ø³Ø·Ø±)\nÙ…Ø«Ø§Ù„:\nhttp://user:pass@gate.netnut.io:24123",
        height=150,
        disabled=not use_proxy
    )

if st.button("ğŸ” Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±", type="primary", use_container_width=True):
    if not products_text.strip():
        st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù†ØªØ¬ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„")
        st.stop()

    products = [p.strip() for p in products_text.split('\n') if p.strip()]
    stores = ["Ø§Ù„Ø¯Ø§Ù†ÙˆØ¨", "ÙƒØ§Ø±ÙÙˆØ±", "Ø¨Ù†Ø¯Ù‡", "Ù„ÙˆÙ„Ùˆ", "Ø§Ù„Ø¹Ø«ÙŠÙ…", "ØªÙ…ÙŠÙ…ÙŠ"]

    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨Ø±ÙˆÙƒØ³ÙŠØ§Øª
    proxy_list = []
    if use_proxy and proxy_input.strip():
        proxy_list = [p.strip() for p in proxy_input.split('\n') if p.strip()]
    if not proxy_list:
        proxy_list = [None]

    progress_bar = st.progress(0)
    status_text = st.empty()
    results = []

    total_tasks = len(products) * len(stores)
    completed = 0

    for product in products:
        row = {"Ø§Ù„Ù…Ù†ØªØ¬": product}
        prices = {}
        links = {}

        for store in stores:
            proxy = random.choice(proxy_list) if proxy_list else None
            status_text.text(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {product} ÙÙŠ {store}...")
            price, link = await scrape_store(product, store, city, proxy)
            prices[store] = price
            links[store] = link
            completed += 1
            progress_bar.progress(completed / total_tasks)
            await asyncio.sleep(0.1)

        for store in stores:
            row[f"{store}_Ø§Ù„Ø³Ø¹Ø±"] = prices[store] if prices[store] else "ØºÙŠØ± Ù…ØªÙˆÙØ±"
            row[f"{store}_Ø§Ù„Ø±Ø§Ø¨Ø·"] = links[store] if links[store] else ""

        # Ø£Ø±Ø®Øµ Ø³Ø¹Ø±
        valid_prices = {k: v for k, v in prices.items() if v}
        if valid_prices:
            best_store = min(valid_prices, key=valid_prices.get)
            row["Ø£Ø±Ø®Øµ Ø³Ø¹Ø±"] = valid_prices[best_store]
            row["Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø£Ø±Ø®Øµ"] = best_store
            row["Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬"] = links[best_store]
        else:
            row["Ø£Ø±Ø®Øµ Ø³Ø¹Ø±"] = "ØºÙŠØ± Ù…ØªÙˆÙØ±"
            row["Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø£Ø±Ø®Øµ"] = "â€”"
            row["Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬"] = ""

        results.append(row)

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    df = pd.DataFrame(results)
    st.success("ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ø¨Ø­Ø«!")
    st.dataframe(df[["Ø§Ù„Ù…Ù†ØªØ¬", "Ø£Ø±Ø®Øµ Ø³Ø¹Ø±", "Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø£Ø±Ø®Øµ", "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬"]], use_container_width=True)

    # ØªÙ‚Ø³ÙŠÙ… Ø­Ø³Ø¨ Ø§Ù„Ù…ØªØ¬Ø±
    st.markdown("### Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù‚Ø³Ù…Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø£Ø±Ø®Øµ")
    grouped = df[df["Ø£Ø±Ø®Øµ Ø³Ø¹Ø±"] != "ØºÙŠØ± Ù…ØªÙˆÙØ±"].groupby("Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø£Ø±Ø®Øµ")
    total_saving = 0

    for store_name, group in grouped:
        total = group["Ø£Ø±Ø®Øµ Ø³Ø¹Ø±"].sum()
        total_saving += total
        with st.expander(f"ğŸª {store_name} â€¢ {len(group)} Ù…Ù†ØªØ¬Ø§Øª â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total:,.2f} Ø±.Ø³", expanded=True):
            list_text = "\n".join([f"â€¢ {row['Ø§Ù„Ù…Ù†ØªØ¬']} - {row['Ø£Ø±Ø®Øµ Ø³Ø¹Ø±']} Ø±.Ø³" for _, row in group.iterrows()])
            st.write(list_text)
            col1, col2 = st.columns(2)
            with col1:
                st.code(list_text, language="text")
            with col2:
                links = " ".join([f"window.open('{row['Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬']}')" for _, row in group.iterrows()])
                st.markdown(f"<button onclick=\"{links}\">ÙØªØ­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·</button>", unsafe_allow_html=True)

    # ØªØµØ¯ÙŠØ±
    csv = df.to_csv(index=False).encode()
    st.download_button("ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„ Ø¥Ù„Ù‰ Excel", csv, "Ù…Ù‚Ø§Ø±Ù†Ø©_Ø§Ù„Ø£Ø³Ø¹Ø§Ø±.csv", "text/csv")

# ØªØ°ÙŠÙŠÙ„
st.markdown("---")
st.caption("Ù…Ø·ÙˆØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªÙ‚Ø¯Ù… 2025 | ÙŠØ¹Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ Cloudflare ÙˆØ¬Ù…ÙŠØ¹ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø­Ù…Ø§ÙŠØ©")
